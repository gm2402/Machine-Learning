{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_table('SMSSpamCollection',names=['Target','Text'])\n",
    "#If data does not have any .format read it by using read_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                               Text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text=''.join(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term=text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term=[t for t in term if len(t)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want=[]\n",
    "#for i in term:\n",
    "    #if i.isalpha():\n",
    "        #want.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want=set(want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want=list(want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd way of cleaning data for spam or ham\n",
    "df['Text']=df['Text'].apply(lambda x:\" \".join(x.lower() for x in x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                               Text\n",
       "0    ham  go until jurong point, crazy.. available only ...\n",
       "1    ham                      ok lar... joking wif u oni...\n",
       "2   spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3    ham  u dun say so early hor... u c already then say...\n",
       "4    ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "df['Text']=df['Text'].apply(lambda x:BeautifulSoup(x).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go until jurong point, crazy.. available only ...\n",
       "1                        ok lar... joking wif u oni...\n",
       "2    free entry in 2 a wkly comp to win fa cup fina...\n",
       "3    u dun say so early hor... u c already then say...\n",
       "4    nah i don't think he goes to usf, he lives aro...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point, crazy.. available only ...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3       u dun say so early hor... u c already then say...\n",
       "4       nah i don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                 will ü b going to esplanade fr home?\n",
       "5569    pity, * was in mood for that. so...any other s...\n",
       "5570    the guy did some bitching but i acted like i'd...\n",
       "5571                           rofl. its true to its name\n",
       "Name: Text, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['Text']=df['Text'].apply(lambda x:re.sub('http\\s',\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                               Text\n",
       "0    ham  go until jurong point, crazy.. available only ...\n",
       "1    ham                      ok lar... joking wif u oni...\n",
       "2   spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3    ham  u dun say so early hor... u c already then say...\n",
       "4    ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER-19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4713</td>\n",
       "      <td>ham</td>\n",
       "      <td>thats cool princess! i will cover your face in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3811</td>\n",
       "      <td>ham</td>\n",
       "      <td>aight, can you text me the address?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5227</td>\n",
       "      <td>ham</td>\n",
       "      <td>i re-met alex nichols from middle school and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4535</td>\n",
       "      <td>ham</td>\n",
       "      <td>i have no money 4 steve mate! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>ham</td>\n",
       "      <td>wot u wanna do then missy?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text\n",
       "4713    ham  thats cool princess! i will cover your face in...\n",
       "3811    ham                aight, can you text me the address?\n",
       "5227    ham  i re-met alex nichols from middle school and i...\n",
       "4535    ham                    i have no money 4 steve mate! !\n",
       "570     ham                         wot u wanna do then missy?"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Text']=df['Text'].apply(lambda x:re.sub(' +','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2236</td>\n",
       "      <td>ham</td>\n",
       "      <td>si.como no?!listened2the plaid album-quite gd&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1276</td>\n",
       "      <td>ham</td>\n",
       "      <td>wot u up 2 u weirdo?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>ham</td>\n",
       "      <td>do you know where my lab goggles went</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4153</td>\n",
       "      <td>ham</td>\n",
       "      <td>what's nannys address?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2443</td>\n",
       "      <td>ham</td>\n",
       "      <td>i donno if they are scorable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text\n",
       "2236    ham  si.como no?!listened2the plaid album-quite gd&...\n",
       "1276    ham                               wot u up 2 u weirdo?\n",
       "572     ham              do you know where my lab goggles went\n",
       "4153    ham                             what's nannys address?\n",
       "2443    ham                       i donno if they are scorable"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Text']=df['Text'].apply(lambda x:len(x)>2 for x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Text']=df[df['Text'].apply(lambda x:len(x)>2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point, crazy.. available only ...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3       u dun say so early hor... u c already then say...\n",
       "4       nah i don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                 will ü b going to esplanade fr home?\n",
       "5569    pity, * was in mood for that. so...any other s...\n",
       "5570    the guy did some bitching but i acted like i'd...\n",
       "5571                           rofl. its true to its name\n",
       "Name: Text, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3731</td>\n",
       "      <td>ham</td>\n",
       "      <td>i guess you could be as good an excuse as any,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>ham</td>\n",
       "      <td>hanging out with my brother and his family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1678</td>\n",
       "      <td>ham</td>\n",
       "      <td>lol where do u come up with these ideas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5354</td>\n",
       "      <td>ham</td>\n",
       "      <td>aiyo cos i sms ü then ü neva reply so i wait 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>ham</td>\n",
       "      <td>am not interested to do like that.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text\n",
       "3731    ham  i guess you could be as good an excuse as any,...\n",
       "3520    ham         hanging out with my brother and his family\n",
       "1678    ham           lol where do u come up with these ideas?\n",
       "5354    ham  aiyo cos i sms ü then ü neva reply so i wait 4...\n",
       "344     ham                 am not interested to do like that."
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER-19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=stopwords.words('english')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove stepwords from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(lambda x:' '.join([x for x in x.split(' ') if x not in stopwords ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove whitespace - Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(lambda x:' '.join([re.sub('[^A-Za-z]+','',x) for x in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove word with less than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(lambda x:' '.join([x for x in x.split(' ') if len(x)>2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jurong point crazy available bugis great world...\n",
       "1                                   lar joking wif oni\n",
       "2    free entry wkly comp win cup final tkts may te...\n",
       "3                        dun say early hor already say\n",
       "4               nah think goes usf lives around though\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER-19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER-19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Text']=df['Text'].apply(lambda w:' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(w) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3116                                 wait inside car park\n",
       "17           remember spell name yes did naughty make wet\n",
       "4200    cmon babe make horny turn txt fantasy babe hot...\n",
       "2850    chance reality fantasy show call per min ntt l...\n",
       "2357                             nohe joined today itself\n",
       "1395                         still meeting dinner tonight\n",
       "2598            got fujitsu ibm toshiba got lot model say\n",
       "844     urgent call landline complimentary ibiza holid...\n",
       "3998    bored housewives chat date now btnational rate...\n",
       "2324    sorry dude dont know forgot even dan reminded ...\n",
       "507     maybe westshore hyde park village place near h...\n",
       "3414                                             need get\n",
       "4818    too mark taking forever pick prescription pain...\n",
       "5364    call send girls erotic ecstacy pmin stop texts...\n",
       "1522                                    angry happen dear\n",
       "1324        thk shd said plus minus leave line paragraphs\n",
       "1378    double mins double txt price linerental latest...\n",
       "2936                                   yeah got one lined\n",
       "5198    shes fine difficulties phone works mine pls se...\n",
       "3191    neva worry bout truth coz truth lead heart its...\n",
       "3952                              dude realy mising today\n",
       "4421                                      msg leave house\n",
       "2039                                 hey going lesson gym\n",
       "513                                          lol forgiven\n",
       "3915    today accept dayu accept brother sister lover ...\n",
       "228                            hey company elama mudyadhu\n",
       "843     prashanthettan mother passed away last night p...\n",
       "3158                       havent shopping lor juz arrive\n",
       "2835                                  sick still shopping\n",
       "4277                             please send aunty number\n",
       "1262    thank much skyped wit sura didnt get pleasure ...\n",
       "2386    someone contacted dating service entered phone...\n",
       "5514                                         okie lor sat\n",
       "2789                     got wat buy tell need come again\n",
       "4581    engagement fixd next month know really shockin...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].sample(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "df['Text']=df['Text'].apply(lambda w:' '.join([stemmer.stem(w) for w in nltk.word_tokenize(w)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jurong point crazi avail bugi great world buff...\n",
       "1                                        lar joke wif oni\n",
       "2       free entri wkli comp win cup final tkt may tex...\n",
       "3                           dun say earli hor alreadi say\n",
       "4                    nah think goe usf live around though\n",
       "                              ...                        \n",
       "5567    time tri contact pound prize claim easi call n...\n",
       "5568                                     go esplanad home\n",
       "5569                           piti mood that ani suggest\n",
       "5570    guy bitch act like interest buy someth els nex...\n",
       "5571                                       rofl true name\n",
       "Name: Text, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>jurong point crazi avail bugi great world buff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>lar joke wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entri wkli comp win cup final tkt may tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>dun say earli hor alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5567</td>\n",
       "      <td>spam</td>\n",
       "      <td>time tri contact pound prize claim easi call n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5568</td>\n",
       "      <td>ham</td>\n",
       "      <td>go esplanad home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5569</td>\n",
       "      <td>ham</td>\n",
       "      <td>piti mood that ani suggest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>ham</td>\n",
       "      <td>guy bitch act like interest buy someth els nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5571</td>\n",
       "      <td>ham</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text\n",
       "0       ham  jurong point crazi avail bugi great world buff...\n",
       "1       ham                                   lar joke wif oni\n",
       "2      spam  free entri wkli comp win cup final tkt may tex...\n",
       "3       ham                      dun say earli hor alreadi say\n",
       "4       ham               nah think goe usf live around though\n",
       "...     ...                                                ...\n",
       "5567   spam  time tri contact pound prize claim easi call n...\n",
       "5568    ham                                   go esplanad home\n",
       "5569    ham                         piti mood that ani suggest\n",
       "5570    ham  guy bitch act like interest buy someth els nex...\n",
       "5571    ham                                     rofl true name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can i apply LabelEncoder on Text\n",
    "#You can apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target']=df['Target'].map({'spam':1,'ham':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23eb3db3188>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['Text']]\n",
    "y=df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115,)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect=vect.fit_transform(X_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer takes 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x5872 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 34018 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect=vect.transform(X_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1115x5872 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7840 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aah',\n",
       " 'aaooooright',\n",
       " 'aathilov',\n",
       " 'aathiwher',\n",
       " 'abbey',\n",
       " 'abdomen',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'abil',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'abl',\n",
       " 'abnorm',\n",
       " 'about',\n",
       " 'abroad',\n",
       " 'absenc',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abus',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accentur',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accommod',\n",
       " 'accommodationvouch',\n",
       " 'accomod',\n",
       " 'accordin',\n",
       " 'accordingli',\n",
       " 'accordinglyor',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'ach',\n",
       " 'achiev',\n",
       " 'acknowledg',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'acwicmbcktzr',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addi',\n",
       " 'addict',\n",
       " 'address',\n",
       " 'addressu',\n",
       " 'adewal',\n",
       " 'adi',\n",
       " 'adjust',\n",
       " 'admin',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'ador',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'adrink',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'adventur',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'aeronaut',\n",
       " 'aeroplan',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'aftr',\n",
       " 'again',\n",
       " 'againcal',\n",
       " 'againlov',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'ageperwksub',\n",
       " 'ageppermesssubscript',\n",
       " 'agesr',\n",
       " 'agidhan',\n",
       " 'ago',\n",
       " 'agocusoon',\n",
       " 'agre',\n",
       " 'agreen',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahnow',\n",
       " 'ahold',\n",
       " 'ahth',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airtel',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'ajith',\n",
       " 'aka',\n",
       " 'akonlon',\n",
       " 'alaikkumprid',\n",
       " 'alaipayuth',\n",
       " 'albi',\n",
       " 'album',\n",
       " 'albumquit',\n",
       " 'alcohol',\n",
       " 'aldrin',\n",
       " 'alert',\n",
       " 'alertfrom',\n",
       " 'alett',\n",
       " 'alex',\n",
       " 'alfi',\n",
       " 'algarv',\n",
       " 'algebra',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alian',\n",
       " 'alibi',\n",
       " 'aliv',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allahrakhesh',\n",
       " 'allday',\n",
       " 'allo',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alreadi',\n",
       " 'alreadysabarish',\n",
       " 'alright',\n",
       " 'alrightokay',\n",
       " 'alrit',\n",
       " 'alritehav',\n",
       " 'also',\n",
       " 'alsoor',\n",
       " 'alter',\n",
       " 'alternativehop',\n",
       " 'although',\n",
       " 'altocoukwavewaveasp',\n",
       " 'alwa',\n",
       " 'alway',\n",
       " 'alwi',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amaz',\n",
       " 'ambiti',\n",
       " 'ambrithmaduraimet',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amigo',\n",
       " 'amk',\n",
       " 'amma',\n",
       " 'amnow',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amount',\n",
       " 'amplikat',\n",
       " 'ampm',\n",
       " 'amrca',\n",
       " 'amt',\n",
       " 'amus',\n",
       " 'amx',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analysi',\n",
       " 'anand',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andr',\n",
       " 'andro',\n",
       " 'angel',\n",
       " 'angri',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'anjola',\n",
       " 'anna',\n",
       " 'anni',\n",
       " 'anniversari',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'anot',\n",
       " 'anoth',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'answerin',\n",
       " 'answr',\n",
       " 'antelop',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'antibiot',\n",
       " 'anybodi',\n",
       " 'anyhow',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyplac',\n",
       " 'anyth',\n",
       " 'anythi',\n",
       " 'anythin',\n",
       " 'anythingtomorrow',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'aom',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'aphex',\n",
       " 'apnt',\n",
       " 'apo',\n",
       " 'apolog',\n",
       " 'apologis',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appear',\n",
       " 'appi',\n",
       " 'appl',\n",
       " 'applebe',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approx',\n",
       " 'appt',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aproach',\n",
       " 'apt',\n",
       " 'aquariu',\n",
       " 'arab',\n",
       " 'arabian',\n",
       " 'arcad',\n",
       " 'archiv',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'arestaur',\n",
       " 'aretak',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'armenia',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'arnt',\n",
       " 'around',\n",
       " 'arpraveesh',\n",
       " 'arrang',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrow',\n",
       " 'arsen',\n",
       " 'art',\n",
       " 'arti',\n",
       " 'artist',\n",
       " 'arun',\n",
       " 'asa',\n",
       " 'asap',\n",
       " 'asapok',\n",
       " 'asda',\n",
       " 'ash',\n",
       " 'ashley',\n",
       " 'ashwini',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'askin',\n",
       " 'aslamalaikkum',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'asshol',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'asssssholeee',\n",
       " 'assum',\n",
       " 'astn',\n",
       " 'astoundingli',\n",
       " 'astrolog',\n",
       " 'asusu',\n",
       " 'ate',\n",
       " 'athom',\n",
       " 'atlanta',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmsm',\n",
       " 'atroci',\n",
       " 'attach',\n",
       " 'attempt',\n",
       " 'atten',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'atyour',\n",
       " 'auction',\n",
       " 'audiit',\n",
       " 'audit',\n",
       " 'audrey',\n",
       " 'audri',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunti',\n",
       " 'aust',\n",
       " 'australia',\n",
       " 'authoris',\n",
       " 'auto',\n",
       " 'autocorrect',\n",
       " 'ava',\n",
       " 'avail',\n",
       " 'availablei',\n",
       " 'avatar',\n",
       " 'avbl',\n",
       " 'ave',\n",
       " 'aveng',\n",
       " 'avent',\n",
       " 'avenu',\n",
       " 'avin',\n",
       " 'avo',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'axi',\n",
       " 'ayn',\n",
       " 'babe',\n",
       " 'babesozi',\n",
       " 'babi',\n",
       " 'babygoodby',\n",
       " 'babyjontet',\n",
       " 'babysit',\n",
       " 'bac',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bagi',\n",
       " 'bahama',\n",
       " 'bailiff',\n",
       " 'bajarangabali',\n",
       " 'bak',\n",
       " 'bakra',\n",
       " 'bakrid',\n",
       " 'balanc',\n",
       " 'ball',\n",
       " 'baller',\n",
       " 'balloon',\n",
       " 'bambl',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bani',\n",
       " 'bank',\n",
       " 'banneduk',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barbi',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'bari',\n",
       " 'barkley',\n",
       " 'barm',\n",
       " 'barolla',\n",
       " 'barrel',\n",
       " 'barri',\n",
       " 'base',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'basq',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batsman',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bawl',\n",
       " 'bay',\n",
       " 'bbc',\n",
       " 'bbd',\n",
       " 'bbdelux',\n",
       " 'bbdtht',\n",
       " 'bblue',\n",
       " 'bbq',\n",
       " 'bcaz',\n",
       " 'bck',\n",
       " 'bcm',\n",
       " 'bcmsfwcnxx',\n",
       " 'bcmwcnxx',\n",
       " 'bcoz',\n",
       " 'bcum',\n",
       " 'bcz',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'bead',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'bec',\n",
       " 'becaus',\n",
       " 'becausethey',\n",
       " 'becom',\n",
       " 'becoz',\n",
       " 'becz',\n",
       " 'bed',\n",
       " 'bedbut',\n",
       " 'bedreal',\n",
       " 'bedrm',\n",
       " 'bedroom',\n",
       " 'beeen',\n",
       " 'beehoon',\n",
       " 'been',\n",
       " 'beendrop',\n",
       " 'beer',\n",
       " 'beerag',\n",
       " 'beerr',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'beggar',\n",
       " 'begin',\n",
       " 'behalf',\n",
       " 'behav',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'believ',\n",
       " 'beliv',\n",
       " 'bell',\n",
       " 'bellearli',\n",
       " 'belli',\n",
       " 'belliger',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'belovd',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'beneficiari',\n",
       " 'benefit',\n",
       " 'bergkamp',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'betta',\n",
       " 'better',\n",
       " 'bettersn',\n",
       " 'bevieswaz',\n",
       " 'bewar',\n",
       " 'beyond',\n",
       " 'bfore',\n",
       " 'bhayandar',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billi',\n",
       " 'billion',\n",
       " 'bilo',\n",
       " 'bin',\n",
       " 'biola',\n",
       " 'bird',\n",
       " 'birla',\n",
       " 'biro',\n",
       " 'birth',\n",
       " 'birthdat',\n",
       " 'birthday',\n",
       " 'bishan',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'blackand',\n",
       " 'blackberri',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blastin',\n",
       " 'bleak',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'blessget',\n",
       " 'blimey',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'bloke',\n",
       " 'blond',\n",
       " 'bloo',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'bloodsend',\n",
       " 'bloomberg',\n",
       " 'bloombergcom',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'bluetoothhdset',\n",
       " 'bluff',\n",
       " 'blur',\n",
       " 'bluray',\n",
       " 'bmw',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'boatin',\n",
       " 'bob',\n",
       " 'bodi',\n",
       " 'bognor',\n",
       " 'bold',\n",
       " 'bollox',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bonu',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookedth',\n",
       " 'bookmark',\n",
       " 'bookshelf',\n",
       " 'boooo',\n",
       " 'boost',\n",
       " 'booti',\n",
       " 'bootydeli',\n",
       " 'borderlin',\n",
       " 'bore',\n",
       " 'bornpleas',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'boughtbraindancea',\n",
       " 'boundari',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxcpm',\n",
       " 'boxnqp',\n",
       " 'boxqu',\n",
       " 'boxwrc',\n",
       " 'boy',\n",
       " 'boyf',\n",
       " 'boyfriend',\n",
       " 'boyi',\n",
       " 'boytoy',\n",
       " 'bra',\n",
       " 'brah',\n",
       " 'brain',\n",
       " 'braini',\n",
       " 'brainless',\n",
       " 'brand',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'bray',\n",
       " 'brb',\n",
       " 'brdget',\n",
       " 'bread',\n",
       " 'breadstick',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breakfast',\n",
       " 'breath',\n",
       " 'breather',\n",
       " 'breez',\n",
       " 'breezi',\n",
       " 'brekki',\n",
       " 'bribe',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brilliant',\n",
       " 'brilliantli',\n",
       " 'brin',\n",
       " 'bring',\n",
       " 'brisk',\n",
       " 'bristol',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broadband',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brolli',\n",
       " 'broth',\n",
       " 'brotha',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'browni',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'browsin',\n",
       " 'bruce',\n",
       " 'brum',\n",
       " 'bruv',\n",
       " 'bslvyl',\n",
       " 'bsn',\n",
       " 'bsnl',\n",
       " 'bstfrnd',\n",
       " 'bthere',\n",
       " 'btnation',\n",
       " 'btnationalr',\n",
       " 'btw',\n",
       " 'btwn',\n",
       " 'bu',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'buen',\n",
       " 'buff',\n",
       " 'buffet',\n",
       " 'buffi',\n",
       " 'bugi',\n",
       " 'build',\n",
       " 'bulb',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'bundl',\n",
       " 'bunker',\n",
       " 'burger',\n",
       " 'burgundi',\n",
       " 'burial',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'burrito',\n",
       " 'buse',\n",
       " 'busetop',\n",
       " 'busi',\n",
       " 'busti',\n",
       " 'busyi',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buz',\n",
       " 'buzi',\n",
       " 'buzz',\n",
       " 'bxipw',\n",
       " 'bye',\n",
       " 'cabin',\n",
       " 'cabl',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calcul',\n",
       " 'cali',\n",
       " 'calicut',\n",
       " 'california',\n",
       " 'call',\n",
       " 'callback',\n",
       " 'callcost',\n",
       " 'calld',\n",
       " 'calldrov',\n",
       " 'caller',\n",
       " 'callertun',\n",
       " 'callfreefon',\n",
       " 'callin',\n",
       " 'callingforgot',\n",
       " 'callon',\n",
       " 'calloptout',\n",
       " 'calloptoutfq',\n",
       " 'calloptouthf',\n",
       " 'calloptoutj',\n",
       " 'calloptoutjq',\n",
       " 'calloptoutlf',\n",
       " 'calloptoutndx',\n",
       " 'calloptoutqf',\n",
       " 'callsmessagesmiss',\n",
       " 'callsminmobsmor',\n",
       " 'callsminmobsmorelkpoboxhpfl',\n",
       " 'callsminmoremobsemspoboxpowa',\n",
       " 'callurg',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camcord',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'cameravideo',\n",
       " 'camp',\n",
       " 'campu',\n",
       " 'camri',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'canal',\n",
       " 'canari',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candont',\n",
       " 'canlov',\n",
       " 'cannam',\n",
       " 'cant',\n",
       " 'cantdo',\n",
       " 'canteen',\n",
       " 'cap',\n",
       " 'capac',\n",
       " 'capit',\n",
       " 'cappuccino',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardiff',\n",
       " 'care',\n",
       " 'careabout',\n",
       " 'career',\n",
       " 'careinsha',\n",
       " 'careless',\n",
       " 'carent',\n",
       " 'careswt',\n",
       " 'careumma',\n",
       " 'carli',\n",
       " 'carlin',\n",
       " 'carlo',\n",
       " 'carolin',\n",
       " 'carpark',\n",
       " 'carri',\n",
       " 'carryin',\n",
       " 'carton',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashbal',\n",
       " 'cashbincouk',\n",
       " 'cashin',\n",
       " 'cashto',\n",
       " 'cast',\n",
       " 'castor',\n",
       " 'casualti',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'categori',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'cave',\n",
       " 'caveboy',\n",
       " 'cbe',\n",
       " 'ccna',\n",
       " 'ccpmin',\n",
       " 'cd',\n",
       " 'cdgt',\n",
       " 'cedar',\n",
       " 'celeb',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'censu',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'centuri',\n",
       " 'cereal',\n",
       " 'ceri',\n",
       " 'certif',\n",
       " 'cha',\n",
       " 'chachi',\n",
       " 'chad',\n",
       " 'chain',\n",
       " 'challeng',\n",
       " 'champ',\n",
       " 'champlaxig',\n",
       " 'champney',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chap',\n",
       " 'chapel',\n",
       " 'chapter',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'chariti',\n",
       " 'charl',\n",
       " 'charli',\n",
       " 'charm',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chastiti',\n",
       " 'chat',\n",
       " 'chatlin',\n",
       " 'chatter',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheat',\n",
       " 'chechi',\n",
       " 'check',\n",
       " 'checkbox',\n",
       " 'checkin',\n",
       " 'checkmat',\n",
       " 'checkup',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'cheeri',\n",
       " 'chees',\n",
       " 'cheesi',\n",
       " 'cheeto',\n",
       " 'chennai',\n",
       " 'chequ',\n",
       " 'cherish',\n",
       " 'cherthalain',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'chex',\n",
       " 'chg',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'chikku',\n",
       " 'chikkuali',\n",
       " 'chikkugo',\n",
       " 'chikkuil',\n",
       " 'chikkuk',\n",
       " 'chikkusimpl',\n",
       " 'chikkuwat',\n",
       " 'child',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chile',\n",
       " 'chill',\n",
       " 'chillaxin',\n",
       " 'chillin',\n",
       " 'china',\n",
       " 'chinatown',\n",
       " 'chinchilla',\n",
       " 'chines',\n",
       " 'chinki',\n",
       " 'chip',\n",
       " 'chitchat',\n",
       " 'chk',\n",
       " 'chloe',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'choos',\n",
       " 'chord',\n",
       " 'chosen',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christma',\n",
       " 'chuck',\n",
       " 'chuckin',\n",
       " 'church',\n",
       " 'ciao',\n",
       " 'cine',\n",
       " 'cinema',\n",
       " 'citi',\n",
       " 'citizen',\n",
       " 'citylink',\n",
       " 'claim',\n",
       " 'claimcod',\n",
       " 'clair',\n",
       " 'clarif',\n",
       " 'clarifi',\n",
       " 'clark',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classmat',\n",
       " 'claypot',\n",
       " 'cld',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearli',\n",
       " 'clever',\n",
       " 'click',\n",
       " 'cliff',\n",
       " 'clip',\n",
       " 'clo',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closebi',\n",
       " 'closer',\n",
       " 'closingd',\n",
       " 'cloth',\n",
       " 'cloud',\n",
       " 'clover',\n",
       " 'club',\n",
       " 'clubmobilescom',\n",
       " 'clue',\n",
       " 'cme',\n",
       " 'cncl',\n",
       " 'cnl',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'coax',\n",
       " 'cocacola',\n",
       " 'coccoon',\n",
       " 'cochin',\n",
       " 'cock',\n",
       " 'cocksuck',\n",
       " 'coco',\n",
       " 'code',\n",
       " 'coffe',\n",
       " 'coimbator',\n",
       " 'coin',\n",
       " 'colani',\n",
       " 'cold',\n",
       " 'coldheard',\n",
       " 'colin',\n",
       " 'collag',\n",
       " 'collaps',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'color',\n",
       " 'colour',\n",
       " 'com',\n",
       " 'comb',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comedi',\n",
       " 'comedyc',\n",
       " 'comfey',\n",
       " 'comfort',\n",
       " 'comin',\n",
       " 'comingtmorow',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'commun',\n",
       " 'comp',\n",
       " 'compani',\n",
       " 'compar',\n",
       " 'compass',\n",
       " 'compens',\n",
       " 'competit',\n",
       " 'complac',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complementari',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'compliment',\n",
       " 'complimentari',\n",
       " 'compofstuff',\n",
       " 'comprehens',\n",
       " 'compromis',\n",
       " 'compulsori',\n",
       " 'comput',\n",
       " ...]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred=lr.predict(X_train_vect)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred=lr.predict(X_test_vect)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3863\n",
      "           1       1.00      0.96      0.98       594\n",
      "\n",
      "    accuracy                           0.99      4457\n",
      "   macro avg       1.00      0.98      0.99      4457\n",
      "weighted avg       0.99      0.99      0.99      4457\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       962\n",
      "           1       0.99      0.87      0.93       153\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.93      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,roc_auc_score\n",
    "print('Train Data')\n",
    "print(classification_report(y_train,y_train_pred))\n",
    "print('Test Data')\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score_train: 0.9813520483983853 auc_score_test: 0.9341207723560665\n"
     ]
    }
   ],
   "source": [
    "auc_score_train=roc_auc_score(y_train,y_train_pred)\n",
    "auc_score_test=roc_auc_score(y_test,y_test_pred)\n",
    "print('auc_score_train:',auc_score_train,'auc_score_test:',auc_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mulnb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulnb.fit(X_train_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred=mulnb.predict(X_train_vect)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred=mulnb.predict(X_train_vect)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3863\n",
      "           1       0.95      0.97      0.96       594\n",
      "\n",
      "    accuracy                           0.99      4457\n",
      "   macro avg       0.97      0.98      0.97      4457\n",
      "weighted avg       0.99      0.99      0.99      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,roc_auc_score\n",
    "print('Train Data')\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score_train: 0.9813520483983853 auc_score_test: 0.9341207723560665\n"
     ]
    }
   ],
   "source": [
    "print('auc_score_train:',auc_score_train,'auc_score_test:',auc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
